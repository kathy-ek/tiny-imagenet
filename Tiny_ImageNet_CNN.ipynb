{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, concatenate\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "MRyCMVt0C9ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ418JTDDCUS",
        "outputId": "d9e927aa-6737-434d-adbe-5f97ee617c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Download the dataset and unzip it\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5erF3oNZc8Ky",
        "outputId": "a0921b76-a921-4f1a-ea8e-0fbdd586d5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-07 19:08:24--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs231n.stanford.edu/tiny-imagenet-200.zip [following]\n",
            "--2024-05-07 19:08:24--  https://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  24.3MB/s    in 10s     \n",
            "\n",
            "2024-05-07 19:08:34 (23.7 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmrnNojJc-7t",
        "outputId": "a170d6c8-1214-4a0b-c61d-920005bfadcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data  tiny-imagenet-200  tiny-imagenet-200.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input image dimensions\n",
        "img_height, img_width, channels = 64, 64, 3\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 200\n",
        "epochs = 24\n",
        "num_train = 100000\n",
        "num_validation = 10000\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    './tiny-imagenet-200/train/',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1AZnw72DEvL",
        "outputId": "f0ec889e-f6eb-42f2-920b-4ff97355a527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None,\n",
        "                       names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "EuVhY2mIDI8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(\n",
        "    val_data, directory='./tiny-imagenet-200/val/images/',\n",
        "    x_col='File', y_col='Class',\n",
        "    target_size=(img_width, img_height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzMNo_KADKlu",
        "outputId": "40a713d8-0583-43a3-f462-c7dcb66718af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 validated image filenames belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "input = Input(shape=(img_height, img_width, channels))\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Creating the sequential model\n",
        "model = Sequential([\n",
        "    # First convolutional block\n",
        "    Conv2D(32, (3, 3), padding='same', kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4), input_shape=(img_height, img_width, channels)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "\n",
        "    # Second convolutional block\n",
        "    Conv2D(128, (3, 3), padding='same', kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Third convolutional block\n",
        "    Conv2D(256, (3, 3), padding='same', kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Fourth convolutional block\n",
        "    Conv2D(512, (3, 3), padding='same', kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Classification layer\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJq9Ixx7DNJs",
        "outputId": "973b15bb-2201-42e8-cae8-ce094cc98546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 64, 64, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 128)       36992     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 64, 64, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 32, 32, 128)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 512)       2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               102600    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1619528 (6.18 MB)\n",
            "Trainable params: 1617672 (6.17 MB)\n",
            "Non-trainable params: 1856 (7.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/model.hdf5\", verbose=1, save_best_only=True)\n",
        "\n",
        "# Fit the Model\n",
        "model.fit(train_generator,\n",
        "          epochs=epochs,\n",
        "          steps_per_epoch=num_train // batch_size,\n",
        "          validation_data=validation_generator,\n",
        "          validation_steps=num_validation // batch_size,\n",
        "          callbacks=[checkpointer],\n",
        "          verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0JBm7ySDPRp",
        "outputId": "ec51cec1-1abf-4a80-cd73-4c6f3d7f2794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 4.4057 - accuracy: 0.1144\n",
            "Epoch 1: val_loss improved from inf to 4.12119, saving model to /content/drive/My Drive/Colab Notebooks/model.hdf5\n",
            "781/781 [==============================] - 122s 142ms/step - loss: 4.4057 - accuracy: 0.1144 - val_loss: 4.1212 - val_accuracy: 0.1429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 3.7606 - accuracy: 0.2018\n",
            "Epoch 2: val_loss did not improve from 4.12119\n",
            "781/781 [==============================] - 105s 135ms/step - loss: 3.7606 - accuracy: 0.2018 - val_loss: 4.2685 - val_accuracy: 0.1538\n",
            "Epoch 3/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 3.4666 - accuracy: 0.2548\n",
            "Epoch 3: val_loss improved from 4.12119 to 3.92413, saving model to /content/drive/My Drive/Colab Notebooks/model.hdf5\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 3.4666 - accuracy: 0.2548 - val_loss: 3.9241 - val_accuracy: 0.1879\n",
            "Epoch 4/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 3.2760 - accuracy: 0.2929\n",
            "Epoch 4: val_loss did not improve from 3.92413\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 3.2760 - accuracy: 0.2929 - val_loss: 4.0803 - val_accuracy: 0.1928\n",
            "Epoch 5/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 3.1286 - accuracy: 0.3210\n",
            "Epoch 5: val_loss improved from 3.92413 to 3.83720, saving model to /content/drive/My Drive/Colab Notebooks/model.hdf5\n",
            "781/781 [==============================] - 109s 139ms/step - loss: 3.1286 - accuracy: 0.3210 - val_loss: 3.8372 - val_accuracy: 0.2098\n",
            "Epoch 6/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 3.0127 - accuracy: 0.3443\n",
            "Epoch 6: val_loss improved from 3.83720 to 3.69184, saving model to /content/drive/My Drive/Colab Notebooks/model.hdf5\n",
            "781/781 [==============================] - 109s 140ms/step - loss: 3.0127 - accuracy: 0.3443 - val_loss: 3.6918 - val_accuracy: 0.2284\n",
            "Epoch 7/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.9109 - accuracy: 0.3666\n",
            "Epoch 7: val_loss improved from 3.69184 to 3.43753, saving model to /content/drive/My Drive/Colab Notebooks/model.hdf5\n",
            "781/781 [==============================] - 109s 140ms/step - loss: 2.9109 - accuracy: 0.3666 - val_loss: 3.4375 - val_accuracy: 0.2695\n",
            "Epoch 8/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.8234 - accuracy: 0.3865\n",
            "Epoch 8: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.8234 - accuracy: 0.3865 - val_loss: 4.4961 - val_accuracy: 0.1999\n",
            "Epoch 9/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.7469 - accuracy: 0.4029\n",
            "Epoch 9: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 139ms/step - loss: 2.7469 - accuracy: 0.4029 - val_loss: 4.2373 - val_accuracy: 0.2100\n",
            "Epoch 10/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.6719 - accuracy: 0.4217\n",
            "Epoch 10: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.6719 - accuracy: 0.4217 - val_loss: 3.6285 - val_accuracy: 0.2713\n",
            "Epoch 11/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.6044 - accuracy: 0.4376\n",
            "Epoch 11: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 139ms/step - loss: 2.6044 - accuracy: 0.4376 - val_loss: 4.6748 - val_accuracy: 0.2012\n",
            "Epoch 12/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.5438 - accuracy: 0.4513\n",
            "Epoch 12: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.5438 - accuracy: 0.4513 - val_loss: 4.0931 - val_accuracy: 0.2551\n",
            "Epoch 13/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.4841 - accuracy: 0.4660\n",
            "Epoch 13: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 139ms/step - loss: 2.4841 - accuracy: 0.4660 - val_loss: 4.1299 - val_accuracy: 0.2261\n",
            "Epoch 14/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.4278 - accuracy: 0.4812\n",
            "Epoch 14: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 139ms/step - loss: 2.4278 - accuracy: 0.4812 - val_loss: 4.2272 - val_accuracy: 0.2225\n",
            "Epoch 15/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.3682 - accuracy: 0.4939\n",
            "Epoch 15: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.3682 - accuracy: 0.4939 - val_loss: 4.8839 - val_accuracy: 0.2055\n",
            "Epoch 16/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.3154 - accuracy: 0.5077\n",
            "Epoch 16: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.3154 - accuracy: 0.5077 - val_loss: 3.9219 - val_accuracy: 0.2702\n",
            "Epoch 17/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.2651 - accuracy: 0.5211\n",
            "Epoch 17: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 109s 139ms/step - loss: 2.2651 - accuracy: 0.5211 - val_loss: 4.0123 - val_accuracy: 0.2650\n",
            "Epoch 18/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.2152 - accuracy: 0.5351\n",
            "Epoch 18: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.2152 - accuracy: 0.5351 - val_loss: 3.6229 - val_accuracy: 0.2939\n",
            "Epoch 19/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.1625 - accuracy: 0.5494\n",
            "Epoch 19: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 109s 139ms/step - loss: 2.1625 - accuracy: 0.5494 - val_loss: 4.1518 - val_accuracy: 0.2612\n",
            "Epoch 20/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.1087 - accuracy: 0.5619\n",
            "Epoch 20: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.1087 - accuracy: 0.5619 - val_loss: 4.6910 - val_accuracy: 0.2670\n",
            "Epoch 21/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.0639 - accuracy: 0.5734\n",
            "Epoch 21: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 139ms/step - loss: 2.0639 - accuracy: 0.5734 - val_loss: 3.8857 - val_accuracy: 0.2950\n",
            "Epoch 22/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.0146 - accuracy: 0.5868\n",
            "Epoch 22: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 2.0146 - accuracy: 0.5868 - val_loss: 4.6265 - val_accuracy: 0.2241\n",
            "Epoch 23/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.9663 - accuracy: 0.6005\n",
            "Epoch 23: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 107s 137ms/step - loss: 1.9663 - accuracy: 0.6005 - val_loss: 4.1160 - val_accuracy: 0.2797\n",
            "Epoch 24/24\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.9220 - accuracy: 0.6119\n",
            "Epoch 24: val_loss did not improve from 3.43753\n",
            "781/781 [==============================] - 106s 136ms/step - loss: 1.9220 - accuracy: 0.6119 - val_loss: 4.5249 - val_accuracy: 0.2684\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d371ea0f130>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}